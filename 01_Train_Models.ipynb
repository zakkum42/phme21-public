{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for PHME21 Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_path = 'input/training_validation_2/fields.csv'\n",
    "fields_df = pd.read_csv(fields_path)\n",
    "fields_df.columns = ['name', 'f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6']\n",
    "\n",
    "fields_dict = {}\n",
    "\n",
    "for idx in range(fields_df.shape[0]):\n",
    "    name = fields_df.loc[idx, 'name']\n",
    "\n",
    "    _fields = []\n",
    "\n",
    "    for f in fields_df.columns[1:]:\n",
    "        if not (str(fields_df.loc[idx, f]) == 'nan'):\n",
    "            _fields.append(name + \"_\" + str(fields_df.loc[idx, f]))\n",
    "\n",
    "    fields_dict[idx] = {'name': fields_df.loc[idx, 'name'], 'fields': _fields}\n",
    "    \n",
    "# fields_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class id and run id from filename\n",
    "def parse_class_name(fname):\n",
    "    p = re.compile(\"^class[^\\d]*(\\d+)_(\\d+).*.csv\")\n",
    "    m = p.match(fname)\n",
    "\n",
    "    return m.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_df(df):\n",
    "\n",
    "    df = df.interpolate(limit_direction='both')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one data file and return in a data frame\n",
    "def load_data_file(path, fname):\n",
    "    fullpath = join(path, fname)\n",
    "    df = pd.read_csv(fullpath)\n",
    "    df.columns = ['name', 'data']\n",
    "\n",
    "    dfx = []\n",
    "\n",
    "    for f in fields_dict:\n",
    "        name = fields_dict[f]['name']\n",
    "        fields = fields_dict[f]['fields']\n",
    "\n",
    "        data = eval(df.loc[f, 'data'])  # convert data to array\n",
    "\n",
    "        new_df = pd.DataFrame(data)\n",
    "        if (f == 33) and (new_df.shape[1] == 6):  # NumberFuseDetected has a special case!\n",
    "            new_df[6] = new_df[5]\n",
    "            new_df[5] = np.NaN\n",
    "\n",
    "        new_df.columns = fields_dict[f]['fields']\n",
    "\n",
    "        dfx.append(new_df)\n",
    "\n",
    "    merged_df = pd.concat(dfx, axis=1)  # Merge columns\n",
    "\n",
    "    # # Do some imputation on the data file\n",
    "    # merged_df = impute_df(merged_df.copy())\n",
    "\n",
    "    c, r = parse_class_name(fname)  # Get class id and run id\n",
    "\n",
    "    # Add class labels and run id\n",
    "    merged_df['class'] = int(c)\n",
    "    merged_df['run'] = int(r)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files from a directory and return merged data frame\n",
    "def load_data_files(path):\n",
    "    print(\"In\", path)\n",
    "    files = []\n",
    "    for f in listdir(path):\n",
    "        if (isfile(join(path, f)) and (f.startswith(\"class\"))):\n",
    "            files.append(f)\n",
    "\n",
    "    data_df_list = []\n",
    "    for fname in files:\n",
    "        print(\"Loading:\", fname)\n",
    "\n",
    "        df = load_data_file(path, fname)\n",
    "\n",
    "        data_df_list.append(df)\n",
    "\n",
    "    data_df = pd.concat(data_df_list, axis=0)  # Merge data frames\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_1 = load_data_files(\"input/training_validation_1/\")\n",
    "data_df_2 = load_data_files(\"input/training_validation_2/\")\n",
    "data_df_3 = load_data_files(\"input/ModelRefinement/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat([data_df_1, data_df_2, data_df_3], axis=0, ignore_index=True)\n",
    "df = data_df.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_cols = []\n",
    "first_cols = df.columns.tolist()\n",
    "df = df.dropna(thresh=int(df.shape[0] * 0.7), axis=1)  # Drop column if it does not have at least x values that are **not** NaN\n",
    "print(\"col: \", df.shape)\n",
    "droped_cols.extend(list(set(first_cols).difference(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(droped_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_values(data, name, fields):\n",
    "\n",
    "    field_df = data[fields]\n",
    "\n",
    "    if field_df.isnull().values.any():\n",
    "        data[fields] = field_df.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    return data[fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in fields_dict:\n",
    "\n",
    "    name = fields_dict[f]['name']\n",
    "    fields = fields_dict[f]['fields']\n",
    "\n",
    "#     print(\"\\nname:\", name, \"fields:\", fields)\n",
    "    fields = list(set(fields).difference(droped_cols))\n",
    "    df_ = df.groupby([\"class\", \"run\"]).apply(fill_nan_values, name, fields)\n",
    "    df_.reset_index(drop=True, inplace=True)\n",
    "    df[fields] = df_[fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if column not in [\"class\", \"run\"]:\n",
    "        if (len(df[column].unique()) == 1) or (df[column].isnull().all()):\n",
    "            df.drop(column, inplace=True, axis=1)\n",
    "            droped_cols.append(column)\n",
    "            print(column, \"droped-unique\")\n",
    "\n",
    "        else:\n",
    "            zero_rows = df.loc[df[column] == float(0)]\n",
    "            if zero_rows.shape[0] >= df.shape[0] * 50:\n",
    "                df.drop(column, inplace=True, axis=1)\n",
    "                droped_cols.append(column)\n",
    "                print(column, \"droped-zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['runId'] = 1000 * df['class'] + df['run']\n",
    "run_df = df[['class', 'runId']].copy()\n",
    "run_df.drop_duplicates(inplace=True)\n",
    "run_df.reset_index(inplace=True)\n",
    "run_df_ = df['run'].copy()\n",
    "del run_df['index'], df['run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.read_pickle(\"feature_importance_df.pkl\")\n",
    "importance_df = importance_df.loc[(importance_df[\"importance_mean\"] > 0)]\n",
    "\n",
    "sorted_features_imp = list(importance_df[\"feature\"].values)\n",
    "value_features_imp = list(importance_df[\"importance_mean\"].values)\n",
    "f_imp = [(name, value) for name, value in zip(sorted_features_imp, value_features_imp)]\n",
    "\n",
    "print(len(sorted_features_imp), sorted_features_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorted_features_imp = ['Temperature_value', 'Humidity_value', 'DurationTestBenchClosed_vFreq', 'FuseHeatSlopeNOK_vMin', 'Pressure_vMax', 'FeederAction4_vCnt', 'ProcessCpuLoadNormalized_value', 'Vacuum_vFreq', 'TotalMemoryConsumption_vMin', 'CpuTemperature_vStd', 'SmartMotorPositionError_vMax', 'FuseCycleDuration_vMax', 'LightBarrierActiveTaskDuration1_vTrend', 'DurationRobotFromFeederToTestBench_vMin', 'SmartMotorSpeed_vMax', 'FusePicked_vFreq', 'DurationPickToPick_vFreq', 'DurationTestBenchClosed_value', 'DurationPickToPick_vTrend', 'VacuumValveClosed_vStd', 'LightBarrierPassiveTaskDuration1_vCnt', 'DurationRobotFromTestBenchToFeeder_vMin', 'NumberFuseEstimated_vFreq', 'VacuumFusePicked_vFreq', 'FuseTestResult_vStd', 'EPOSCurrent_vStd', 'DurationTestBenchClosed_vMin', 'VacuumFusePicked_vMin', 'TemperatureThermoCam_value', 'SmartMotorPositionError_vFreq', 'LightBarrierActiveTaskDuration1_vMax', 'IntensityTotalThermoImage_vMax', 'DurationRobotFromFeederToTestBench_vStd', 'TemperatureThermoCam_vTrend', 'EPOSVelocity_vStd', 'ProcessMemoryConsumption_vStd', 'VacuumFusePicked_vCnt', 'FuseHeatSlopeNOK_vFreq', 'FuseCycleDuration_vCnt', 'Vacuum_vTrend', 'LightBarrierActiveTaskDuration1_vStd', 'FuseCycleDuration_vMin', 'DurationRobotFromTestBenchToFeeder_vTrend', 'FuseHeatSlope_vMax', 'FusePicked_vMin', 'DurationTestBenchClosed_vCnt', 'SmartMotorPositionError_vTrend', 'SmartMotorSpeed_vFreq', 'Vacuum_vMax', 'Pressure_vMin', 'Vacuum_value', 'VacuumFusePicked_value', 'Pressure_vFreq', 'FuseOutsideOperationalSpace_vCnt', 'FuseHeatSlopeNOK_vMax', 'EPOSVelocity_vTrend', 'NumberFuseEstimated_vCnt', 'Vacuum_vStd', 'EPOSCurrent_vTrend', 'FuseOutsideOperationalSpace_vFreq', 'EPOSVelocity_vFreq', 'VacuumValveClosed_value', 'LightBarrierActiveTaskDuration1_vCnt', 'FuseHeatSlope_value', 'ValidFrame_vCnt', 'Vacuum_vCnt', 'TotalMemoryConsumption_vMax', 'Vacuum_vMin', 'TotalMemoryConsumption_vStd', 'ProcessCpuLoadNormalized_vMax', 'EPOSCurrent_vMax', 'TotalCpuLoadNormalized_vStd', 'ValidFrameOptrisPIIRCamera_vFreq', 'FusePicked_vTrend', 'DurationRobotFromTestBenchToFeeder_vFreq', 'FuseCycleDuration_value', 'EPOSCurrent_vMin', 'VacuumValveClosed_vMin', 'FeederAction2_vCnt', 'DurationPickToPick_vMax', 'FuseCycleDuration_vFreq', 'LightBarrierPassiveTaskDuration1_vStd', 'NumberFuseDetected_vFreq', 'DurationTestBenchClosed_vTrend', 'LightBarrierActiveTaskDuration1_vMin', 'DurationRobotFromFeederToTestBench_vMax', 'FusePicked_vCnt', 'EPOSVelocity_vCnt', 'DurationPickToPick_vCnt', 'FuseHeatSlope_vMin', 'SmartMotorPositionError_vStd', 'SmartMotorPositionError_vMin', 'EPOSVelocity_vMax', 'EPOSPosition_vMin', 'TemperatureThermoCam_vStd', 'DurationRobotFromFeederToTestBench_vFreq', 'FuseHeatSlope_vTrend', 'EPOSVelocity_vMin', 'SmartMotorSpeed_value', 'LightBarrierActiveTaskDuration1_value', 'FuseTestResult_value', 'VacuumFusePicked_vTrend', 'FusePicked_vStd', 'EPOSPosition_vTrend', 'VacuumValveClosed_vFreq', 'LightBarrierPassiveTaskDuration1_vTrend', 'ValidFrameOptrisPIIRCamera_vCnt', 'DurationRobotFromTestBenchToFeeder_vCnt', 'LightBarrierActiveTaskDuration1_vFreq', 'FuseTestResult_vFreq', 'EPOSPosition_vFreq', 'IntensityTotalImage_vFreq', 'EPOSCurrent_vFreq', 'FeederBackgroundIlluminationIntensity_vCnt', 'DurationRobotFromTestBenchToFeeder_value', 'EPOSCurrent_value', 'DurationPickToPick_vStd', 'SmartMotorSpeed_vTrend', 'FuseCycleDuration_vStd', 'DurationRobotFromFeederToTestBench_vCnt', 'FuseHeatSlope_vStd', 'Pressure_vCnt', 'FuseIntoFeeder_vCnt', 'ValidFrame_vFreq', 'ProcessMemoryConsumption_vMin', 'TotalCpuLoadNormalized_vMax', 'DurationTestBenchClosed_vStd', 'DurationPickToPick_value', 'CpuTemperature_vMin', 'LightBarrierPassiveTaskDuration1_vFreq', 'DurationPickToPick_vMin', 'CpuTemperature_vMax', 'VacuumValveClosed_vMax', 'CpuTemperature_value', 'TotalCpuLoadNormalized_vMin', 'DurationTestBenchClosed_vMax', 'VacuumFusePicked_vStd', 'ProcessMemoryConsumption_vMax', 'EPOSCurrent_vCnt', 'Pressure_value', 'ProcessMemoryConsumption_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def create_sequence(sequence, n_steps):\n",
    "    X = list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequence[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "\n",
    "    return np.array(X)\n",
    "\n",
    "def create_dataset_for_run(df, ws):\n",
    "\n",
    "    sensors_df = df.filter(sensor_list)\n",
    "\n",
    "    # Calculate seq of windows_size len\n",
    "    seq = create_sequence(sensors_df.values, n_steps=ws)\n",
    "    #     seq = np.transpose(seq, axes=(0, 2, 1))\n",
    "    seq_count = seq.shape[0]\n",
    "    seq = seq.reshape((seq_count, -1))  # for 1D\n",
    "\n",
    "    labels = df['class'].values[:seq_count]\n",
    "\n",
    "    return seq, labels\n",
    "\n",
    "def create_datasets(df, ws):\n",
    "    run_list = df['runId'].unique()\n",
    "    l_len_runs = []\n",
    "\n",
    "    X_df_list = []\n",
    "    y_df_list = []\n",
    "\n",
    "    for r in run_list:\n",
    "        r_df = df[df['runId'] == r]\n",
    "        # print (\"--> r: \", r, r_df.shape)\n",
    "        sensor_data, label_data = create_dataset_for_run(r_df, ws)\n",
    "\n",
    "        # Post Processing for the model\n",
    "\n",
    "        # Padding for model input\n",
    "        padded_sensor_data = sensor_data.copy()  # np.hstack((sensor_data, np.zeros((sensor_data.shape[0], 2)))) # for AE\n",
    "\n",
    "        X_t = padded_sensor_data[:]\n",
    "\n",
    "        y_t = label_data[:]\n",
    "\n",
    "        X_df_list.append(pd.DataFrame(X_t))\n",
    "        y_df_list.append(pd.DataFrame(y_t))\n",
    "        l_len_runs.append(len(X_t))\n",
    "\n",
    "    X_t = pd.concat(X_df_list, axis=0)  # Merge data frames\n",
    "    y_t = pd.concat(y_df_list, axis=0)  # Merge data frames\n",
    "\n",
    "    return X_t.values, y_t.values.flatten(), run_list, l_len_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list = sorted_features_imp[:len(sorted_features_imp)].copy()\n",
    "df_report = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold Model evaluations\n",
    "\n",
    "fold_num = 3\n",
    "cv = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=41)\n",
    "\n",
    "ws = 40\n",
    "\n",
    "acc_sum_ = 0\n",
    "f1_sum_ = 0\n",
    "mcc_sum_ = 0\n",
    "\n",
    "print(\"_______________________________________________________________\")\n",
    "\n",
    "for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "    print(\"----------------------------------------------------------\")\n",
    "\n",
    "    report_index = \"ws_{}_fold_{}\".format(ws, fold + 1)\n",
    "    print(\"Fold: \", report_index)\n",
    "\n",
    "    training_runIds = run_df.loc[training_indices]['runId']\n",
    "    validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "\n",
    "    df_ = df.loc[~(df[\"runId\"].isin([56, 74, 49, 23, 35, 6, 83, 54]))]\n",
    "\n",
    "    X_train_df = df_[df_['runId'].isin(training_runIds)].copy()\n",
    "    X_val_df = df_[df_['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "    X_train_df = X_train_df[sensor_list + [\"class\", \"runId\"]].copy()\n",
    "    X_val_df = X_val_df[sensor_list + [\"class\", \"runId\"]].copy()\n",
    "\n",
    "    scaler_cols = sensor_list.copy()  \n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler_data_tr = scaler.fit_transform(X_train_df[scaler_cols])\n",
    "    scaler_data_tr = pd.DataFrame(scaler_data_tr, index=X_train_df.index, columns=scaler_cols)\n",
    "    X_train_df = pd.concat([X_train_df[[\"class\", \"runId\"]], scaler_data_tr], axis=1)\n",
    "\n",
    "    scaler_data_ts = scaler.transform(X_val_df[scaler_cols])\n",
    "    scaler_data_ts = pd.DataFrame(scaler_data_ts, index=X_val_df.index, columns=scaler_cols)\n",
    "    X_val_df = pd.concat([X_val_df[[\"class\", \"runId\"]], scaler_data_ts], axis=1)\n",
    "\n",
    "    X_train, y_train, runList_tr, l_len_runs_tr = create_datasets(X_train_df, ws)\n",
    "    X_val, y_val, runList_val, l_len_runs_val = create_datasets(X_val_df, ws)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    X_train = lda.fit_transform(X_train, y_train)\n",
    "    X_val = lda.transform(X_val)\n",
    "\n",
    "    param = {\n",
    "        'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "        'num_class': len(pd.unique(y_train))}  # the number of classes that exist in this datset\n",
    "\n",
    "    xgb_model = XGBClassifier(param, random_state=35535, verbosity=0)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    pred = xgb_model.predict(X_val)\n",
    "\n",
    "    acc_val = round(accuracy_score(y_val, pred), 3)\n",
    "    f1_val = round(f1_score(y_val, pred, average='weighted'), 3)\n",
    "    mcc_val = round(matthews_corrcoef(y_val, pred), 3)\n",
    "    cm = confusion_matrix(y_val, pred)\n",
    "\n",
    "    acc_sum_ += acc_val\n",
    "    f1_sum_ += f1_val\n",
    "    mcc_sum_ += mcc_val\n",
    "\n",
    "    print(cm)\n",
    "    print(\"XGBClassifier Fold:\", fold, \"ACC:\", acc_val, \"F1:\", f1_val, \"MCC:\", mcc_val)\n",
    "    df_report.loc[report_index, \"XGB_ACC\"] = acc_val\n",
    "    df_report.loc[report_index, \"XGB_F1\"] = f1_val\n",
    "    df_report.loc[report_index, \"XGB_MCC\"] = mcc_val\n",
    "\n",
    "ave_acc = round(acc_sum_ / fold_num, 3)\n",
    "ave_f1_score = round(f1_sum_ / fold_num, 3)\n",
    "ave_mcc = round(mcc_sum_ / fold_num, 3)\n",
    "\n",
    "print(\"\\nXGBM Avg ACC:\", ave_acc, \"Avg F1:\", ave_f1_score, \"Avg MCC:\", ave_mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Training\n",
    "ws = 40\n",
    "\n",
    "acc_sum_4 = 0\n",
    "f1_sum_4 = 0\n",
    "mcc_sum_4 = 0\n",
    "\n",
    "df_ = df.loc[~(df[\"runId\"].isin([56, 74, 49, 23, 35, 6, 83, 54]))]\n",
    "\n",
    "scaler_cols = sensor_list.copy()\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler_data_tr = scaler.fit_transform(df_[scaler_cols])\n",
    "scaler_data_tr = pd.DataFrame(scaler_data_tr, index=df_.index, columns=scaler_cols)\n",
    "X_train_df = pd.concat([df_[[\"class\", \"runId\"]], scaler_data_tr], axis=1)\n",
    "\n",
    "X_train, y_train, runList_tr, l_len_runs_tr = create_datasets(X_train_df, ws)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "l_index = []\n",
    "for run_, num_run in zip(runList_tr, l_len_runs_tr):\n",
    "    l_index.extend([run_] * num_run)\n",
    "\n",
    "param = {\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': len(pd.unique(y_train))}  # the number of classes that exist in this datset\n",
    "\n",
    "xgb_final_model = XGBClassifier(param, random_state=41, verbosity=0)\n",
    "xgb_final_model.fit(X_train, y_train)\n",
    "pred = xgb_final_model.predict(X_train)\n",
    "\n",
    "acc_val = round(accuracy_score(y_train, pred), 3)\n",
    "f1_val = round(f1_score(y_train, pred, average='weighted'), 3)\n",
    "mcc_val = round(matthews_corrcoef(y_train, pred), 3)\n",
    "\n",
    "cm = confusion_matrix(y_train, pred)\n",
    "\n",
    "print(\"XGBClassifier:\", \"ACC:\", acc_val, \"F1:\", f1_val, \"MCC:\", mcc_val)\n",
    "\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for PHME21 Clustering Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.loc[~(df[\"runId\"].isin([56, 74, 49, 23, 35, 6, 83, 54]))]\n",
    "\n",
    "scaler_cols = sensor_list.copy()\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler_data_tr = scaler.fit_transform(df_[scaler_cols])\n",
    "scaler_data_tr = pd.DataFrame(scaler_data_tr, index=df_.index, columns=scaler_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler_data_tr[['Temperature_value', 'Humidity_value']]\n",
    "X_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model = KMeans(n_clusters=2).fit(X_train)\n",
    "y_pred = cluster_model.labels_\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump final models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models_to_submit.pkl', 'wb') as handle:\n",
    "    pickle.dump((fields_dict, sensor_list, scaler, lda, xgb_final_model, cluster_model) , handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
