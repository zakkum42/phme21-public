{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHME21 Data Challenge Submission by Team-GTU\n",
    "## Cluster Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested with\n",
    "* Python 3.7\n",
    "* Scikit-learn 0.23.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from numpy import nan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class id and run id from filename\n",
    "def parse_class_name(fname):\n",
    "    p = re.compile(\"^class[^\\d]*(\\d+)_(\\d+).*.csv\")\n",
    "    m = p.match(fname)\n",
    "\n",
    "    return m.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_files():\n",
    "    \n",
    "    with open(\"models_to_submit.pkl\", \"rb\") as input_file:\n",
    "        l_pickles = pickle.load(input_file)\n",
    "        \n",
    "    fields_dict = l_pickles[0]\n",
    "    sensor_list = l_pickles[1]\n",
    "    scaler = l_pickles[2]\n",
    "    lda = l_pickles[3]\n",
    "    model4 = l_pickles[4]\n",
    "    model = l_pickles[5]\n",
    "                \n",
    "    return fields_dict, sensor_list, scaler, lda, model4, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one data file and return in a data frame\n",
    "def load_data_file(path, fname, fields_dict):\n",
    "    \n",
    "    fullpath = join(path, fname)\n",
    "    df = pd.read_csv(fullpath)\n",
    "    df.columns = ['name', 'data']\n",
    "\n",
    "    dfx = []\n",
    "\n",
    "    for f in fields_dict:\n",
    "        name = fields_dict[f]['name']\n",
    "        fields = fields_dict[f]['fields']\n",
    "\n",
    "        data = eval(df.loc[f, 'data'])  # convert data to array\n",
    "\n",
    "        new_df = pd.DataFrame(data)\n",
    "        if (f == 33) and (new_df.shape[1] == 6):  # NumberFuseDetected has a special case!\n",
    "            new_df[6] = new_df[5]\n",
    "            new_df[5] = np.NaN\n",
    "\n",
    "        new_df.columns = fields_dict[f]['fields']\n",
    "\n",
    "        dfx.append(new_df)\n",
    "\n",
    "    merged_df = pd.concat(dfx, axis=1)  # Merge columns\n",
    "\n",
    "    # # Do some imputation on the data file\n",
    "    # merged_df = impute_df(merged_df.copy())\n",
    "\n",
    "    c, r = parse_class_name(fname)  # Get class id and run id\n",
    "\n",
    "    # Add class labels and run id\n",
    "    merged_df['class'] = int(c)\n",
    "    merged_df['run'] = int(r)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_values(data, name, fields):\n",
    "\n",
    "    field_df = data[fields]\n",
    "\n",
    "    if field_df.isnull().values.any():\n",
    "        data[fields] = field_df.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    return data[fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BONUS POINT: This script is used to assess the performance of the clustering result\n",
    "#Test CreateCluster is the prototype of the function that each team can develop to cluster fault-free experiments\n",
    "#This function must handle all the operation to: read the input files and return the clustering result\n",
    "#Input: \n",
    "# - Folder Name: The name of the folder where the experiment file are stored\n",
    "#Output:\n",
    "# - ExperimentList: the name of the exeperiments in the input Folder. \n",
    "### IMPORTANT: This list must return the experiment in the same order as processed by the clustering. \n",
    "# - ClusterLabels: The cluster ID for each Experiment in the ExperimentList list\n",
    "\n",
    "def CreateCluster(FolderName):\n",
    "\n",
    "    ExperimentList = [f for f in listdir(FolderName) if isfile(join(FolderName, f))]\n",
    "    \n",
    "    ClusterLabels = []\n",
    "    \n",
    "    ws = 40    \n",
    "    \n",
    "    fields_dict, sensor_list, scaler, lda, _, model = load_pickle_files()\n",
    "    \n",
    "    \n",
    "    for Experiment in ExperimentList:\n",
    "        \n",
    "        df = load_data_file(FolderName, Experiment, fields_dict)\n",
    "        # print(df.isnull().sum().any())\n",
    "\n",
    "        for f in fields_dict:\n",
    "            name = fields_dict[f]['name']\n",
    "            fields = fields_dict[f]['fields']\n",
    "\n",
    "            # print(\"\\nname:\", name, \"fields:\", fields)\n",
    "            df_ = df.groupby([\"class\", \"run\"]).apply(fill_nan_values, name, fields)\n",
    "            df_.reset_index(drop=True, inplace=True)\n",
    "            df[fields] = df_[fields]\n",
    "\n",
    "        df = df[sensor_list + [\"class\", \"run\"]]\n",
    "        df = df.rename(columns={'run': 'runId'})\n",
    "\n",
    "        X_test_df = df[sensor_list + [\"class\", \"runId\"]].copy()\n",
    "\n",
    "        scaler_cols = sensor_list.copy()  # list(set(sensor_list).difference([\"class\", \"runId\"]))\n",
    "        # scaler_cols = ['Temperature_value', 'Humidity_value']\n",
    "\n",
    "        scaler_data_ts = scaler.transform(X_test_df[scaler_cols])\n",
    "        scaler_data_ts = pd.DataFrame(scaler_data_ts, index=X_test_df.index, columns=scaler_cols)\n",
    "        X_test = scaler_data_ts[['Temperature_value', 'Humidity_value']]\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        results_dict = Counter(y_pred)\n",
    "        \n",
    "        most_common = dict(results_dict.most_common(1))\n",
    "        true_class = list(most_common.keys())[0]\n",
    "        \n",
    "        ClusterLabels.append(true_class)        \n",
    "    \n",
    "\n",
    "    return ExperimentList, ClusterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logperformance function stores the final performance. Only this performance will be used to compute the Penalty score of each team\n",
    "def LogPerformance(ExperimentList, ClusterLabels):\n",
    "\n",
    "    if not os.path.exists('Cluster_Results'):\n",
    "        os.makedirs('Cluster_Results')\n",
    "        \n",
    "    PerformanceOutput = open(\"Cluster_Results/ClusterPerformance.csv\",\"w\")\n",
    "    PerformanceOutput.write(\"Experiment;ClusterLabel\\n\")\n",
    "    for i in range(len(ExperimentList)):\n",
    "        Experiment   = ExperimentList[i]\n",
    "        ClusterLabel = ClusterLabels[i]\n",
    "        PerformanceOutput.write(Experiment+\";\"+str(ClusterLabel)+\"\\n\")\n",
    "    PerformanceOutput.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Example of the validation pipleline for the BONUS POINT.\n",
    "#Data/ is the folder where the experiment is stored\n",
    "\n",
    "def main():\n",
    "    \n",
    "    FolderName = \"Data_Cluster/\"\n",
    "    ExperimentList, ClusterLabels = CreateCluster(FolderName)\n",
    "    print(ExperimentList, ClusterLabels)\n",
    "    \n",
    "    LogPerformance(ExperimentList, ClusterLabels)\n",
    "    return\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
